{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dYXLNPim8Jiv"
   },
   "outputs": [],
   "source": [
    "# 載入相關套件\n",
    "import os\n",
    "import re, warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e0fSUAvKi01l"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authorize Google SDK to access Google Drive from Colab\n",
    "\n",
    "auth.authenticate_user()\n",
    "qauth = GoogleAuth()\n",
    "qauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(qauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LkWjuxuoi8JA",
    "outputId": "b83b9763-fc13-4fed-ac72-3655a4108fa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IK07o1e7itjj"
   },
   "outputs": [],
   "source": [
    "# 將訓練資料切割成 訓練集 / 驗證集\n",
    "from sklearn.model_selection import train_test_split\n",
    "dir = '/content/drive/My Drive/data/ch30'\n",
    "df =  pd.read_csv(dir + '/train.csv')\n",
    "X = df.text.values\n",
    "y = df.target.values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "0XiZi_RMjWt0",
    "outputId": "9fb72c14-24ce-49f5-d3ca-2d5fb046ebcf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>3420</td>\n",
       "      <td>Everyone starts a #UX project with the best in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>5639</td>\n",
       "      <td>@caseyliss def - and donÛªt even fathom when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>9588</td>\n",
       "      <td>I need a thunder buddy. ????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029</th>\n",
       "      <td>10002</td>\n",
       "      <td>Drunk #BBMeg! ??????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>9213</td>\n",
       "      <td>@PieroCastellano @nipped suicide bombing civil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text\n",
       "1040   3420  Everyone starts a #UX project with the best in...\n",
       "1671   5639  @caseyliss def - and donÛªt even fathom when ...\n",
       "2896   9588                       I need a thunder buddy. ????\n",
       "3029  10002                               Drunk #BBMeg! ??????\n",
       "2773   9213  @PieroCastellano @nipped suicide bombing civil..."
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 載入測試資料\n",
    "test_df = pd.read_csv(dir + '/test.csv')\n",
    "test_df = test_df[['id', 'text']]\n",
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BT_kQ_ZRj1VO",
    "outputId": "8f5c09c4-8f80-45a1-e85e-9386c0a3c2e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "# 載入 pytorch 套件, 依照現有環境判定是否使用 GPU 計算\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1iAJ6BqLj5Xh"
   },
   "outputs": [],
   "source": [
    "# 前處理\n",
    "def text_preprocessing(text):\n",
    "    # 移除推特的姓名標籤 ('@name')\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "    # 將 '&amp;' 替換成 '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "    # 移除文末的空白字元\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdOYVfYlj-Pv",
    "outputId": "5f975fc9-1651-4358-9f5f-bfebeea34cdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  London is cool ;)\n",
      "Processed:  London is cool ;)\n"
     ]
    }
   ],
   "source": [
    "# 印出第一組推文在前處理之前與之後的改變\n",
    "print('Original: ', X[21])\n",
    "print('Processed: ', text_preprocessing(X[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5eimyKFkajI"
   },
   "source": [
    "## BertTokenizer.from_pretrained提供下列5種方法：\n",
    "\n",
    "* bert-base-uncased: 12-layer, 768-hidden, 12-heads, 110M parameters\n",
    "* bert-large-uncased: 24-layer, 1024-hidden, 16-heads, 340M parameters\n",
    "* bert-base-cased: 12-layer, 768-hidden, 12-heads , 110M parameters\n",
    "* bert-base-multilingual: 102 languages, 12-layer, 768-hidden, 12-heads, 110M parameters\n",
    "* bert-base-chinese: Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1cAxi3Nj_wI",
    "outputId": "5004799c-2935-40c3-ae35-f34f17ce2ad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "# 載入 Bert 套件與 tokenizer\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# 設定 Bert 的前處理函數\n",
    "def preprocessing_for_bert(data):\n",
    "    # 初始化要傳回的資料\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    # 把所有文句用 tokenizer 編碼\n",
    "    for sent in data:\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # 套用簡化版前處理函數\n",
    "            add_special_tokens=True,        # 加上 `[CLS]` 與 `[SEP]`\n",
    "            max_length=MAX_LEN,             # 需要填充的最大長度\n",
    "            pad_to_max_length=True,         # 是否要填充到最大長度\n",
    "            return_attention_mask=True      # 是否傳回 attention mask\n",
    "            )        \n",
    "        # 更新要傳回的資料\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "    # 將傳回資料轉為 tensor\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "laE6fAEjkx_D",
    "outputId": "e5456cc3-bd0e-4f2b-a0b0-a715a4757ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  84\n"
     ]
    }
   ],
   "source": [
    "# 將訓練資料與測試資料的\"推文\"合併\n",
    "all_tweets = np.concatenate([df.text.values, test_df.text.values])\n",
    "\n",
    "# 將推文使用 tokenizer 加以編碼\n",
    "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
    "\n",
    "# 找出最大的推文長度 (訓練資料 + 預測目標資料)\n",
    "max_len = max([len(sent) for sent in encoded_tweets])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_5v8H-VvfU7",
    "outputId": "70dcef91-345f-4722-cdc1-c46dca6dd146"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
      "Token IDs:  [101, 2256, 15616, 2024, 1996, 3114, 1997, 2023, 1001, 8372, 2089, 16455, 9641, 2149, 2035, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# 將上一格的 Max length 數值填入\n",
    "MAX_LEN = 84\n",
    "\n",
    "# 顯示第一筆資料的推文與期經過 Bert 的前處理函數 (preprocessing_for_bert) 的編碼結果 (確認函數正確)\n",
    "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
    "print('Original: ', X[0])\n",
    "print('Token IDs: ', token_ids)\n",
    "\n",
    "# 使用 preprocessing_for_bert 將訓練 / 驗證集的推文進行編碼\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "swk0BSrIvkuB"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# 將訓練與驗證目標值轉為 torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "# 要微調 (fine-tuning) BERT 時, 原作者建議的 batch size 為 16 或 32\n",
    "batch_size = 64\n",
    "\n",
    "# 設定訓練與驗證集的 DataLoader\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGESgK0ww-0i",
    "outputId": "b92f6e35-d446-4833-c918-022969888508"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.2 ms, sys: 2.01 ms, total: 23.2 ms\n",
      "Wall time: 22.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 載入 pytorch 與 Bert 相關套件\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "# 自定義 Bert 分類器函數\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # 指定 BERT 輸入長度大小(D_in), 分類器的隱藏層大小(H), 以及分類目標值的種類數量(D_out)\n",
    "        D_in, H, D_out = 768, 128, 2\n",
    "        # 載入 Bert 預訓練權重作為初始值\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # 初始化自定義分類器的類神經網路\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "        # 凍結 Bert 部分的權重\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # 將資料輸入 BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)        \n",
    "        # 將輸出結果存在 last_hidden_state_cls 中\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "        # 將輸出結果輸入自定義分類器\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IovKOVtOx2er"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def initialize_model(epochs=4):\n",
    "    # 初始化 Bert 分類器\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "    # 告訴 PyTorch 模型需要在 GPU 上執行\n",
    "    bert_classifier.to(device)\n",
    "    # 設定 optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # 預設的學習速率\n",
    "                      eps=1e-8    # 預設的 epsilon 值\n",
    "                      )\n",
    "    # 計算總共的訓練步數\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    # 設定學習率排程\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # 預設值\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HvxL_zXXyOIT"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# 設定損失函數\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    # 開始訓練迴圈\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # 印出變數表格標題\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "        # 測量每個 epoch 的執行時間\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "        # 每個 epoch 開始時重置追蹤的變數\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "        # 將模型切換到訓練模式\n",
    "        model.train()\n",
    "        # 訓練資料的每個 batch \n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # 將所有 batch 資料載入 GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "            # 將模型中之前計算的梯度歸零\n",
    "            model.zero_grad()\n",
    "            # 執行一個向前傳遞. 這會傳回一個 logit 值\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "            # 計算並累加損失值\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "            # 執行一個向後傳遞以計算梯度\n",
    "            loss.backward()\n",
    "            # 將梯度侷限在正負 1 範圍內, 防止梯度爆炸\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            # 更新參數與學習率\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            # 每 20 個 batches 印出損失值與執行時間一次\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # 計算 20 batches 的執行時間\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "                # 印出訓練結果\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "                # 重置 batch 追蹤變數\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "        # 計算全部訓練資料的平均損失值\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        if evaluation == True:\n",
    "            # 每個 epoch 訓練完畢後, 在驗證集上檢驗模型的表現\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "            time_elapsed = time.time() - t0_epoch            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    # 將模型切換到評量模式 : 此模式下暫停使用 dropout 層\n",
    "    model.eval()\n",
    "    # 紀錄評量函數\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    # 驗證資料的每個 batch \n",
    "    for batch in val_dataloader:\n",
    "        # 將所有 batch 資料載入 GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "        # 計算 logit 值\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        # 計算損失值\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "        # 取得預測值\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "        # 計算 accuracy 數值\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "    # 計算全部驗證資料的平均損失值與平均 accuracy\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "akZ3xKv3x698",
    "outputId": "14f73f3a-d3d1-4ee6-e2ec-752fa71b16b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.594928   |     -      |     -     |   10.26  \n",
      "   1    |   40    |   0.441820   |     -      |     -     |   9.74   \n",
      "   1    |   60    |   0.433628   |     -      |     -     |   9.73   \n",
      "   1    |   80    |   0.405168   |     -      |     -     |   9.73   \n",
      "   1    |   100   |   0.361499   |     -      |     -     |   9.74   \n",
      "   1    |   107   |   0.386799   |     -      |     -     |   2.99   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.444846   |  0.424221  |   82.26   |   54.09  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.313129   |     -      |     -     |   10.20  \n",
      "   2    |   40    |   0.325050   |     -      |     -     |   9.73   \n",
      "   2    |   60    |   0.292339   |     -      |     -     |   9.73   \n",
      "   2    |   80    |   0.289565   |     -      |     -     |   9.73   \n",
      "   2    |   100   |   0.306253   |     -      |     -     |   9.74   \n",
      "   2    |   107   |   0.457787   |     -      |     -     |   2.98   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.315225   |  0.449913  |   82.01   |   54.03  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "set_seed(42) # 設定隨機種子\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_3D7gHQe13S2"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    # 將模型切換到評量模式 : 此模式下暫停使用 dropout 層\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "\n",
    "    # 測試資料的每個 batch \n",
    "    for batch in test_dataloader:\n",
    "        # 將所有 batch 資料載入 GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "        # 計算機率\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)    \n",
    "    # 將每個 batch 的 logit 值連結起來\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    # 使用 softmax 計算機率\n",
    "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "27sQrQs22Mv7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')       \n",
    "    # 取得測試集的 accuracy 值\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')    \n",
    "    # 繪製 ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "EDbioBAK2NnZ",
    "outputId": "94453c9c-63e8-4052-efca-b959ecc4f9e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8832\n",
      "Accuracy: 82.02%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5gUVdbA4d8hIxJcUFdJooICLgiMJAOYEDHgiiK6oPipqJhBVkyrshhxUXQxILq4roIZcSUtCiIIEgSUIIogSZEgKohDmvP9cWqcZpzp6Qnd1d1z3ufpZ7q7qqtO18z06ap777miqjjnnHP5KRN2AM4555KbJwrnnHNReaJwzjkXlScK55xzUXmicM45F5UnCuecc1F5onCFIiJLRKRj2HEkCxG5Q0RGhrTvUSIyOIx9lzQR+YuITC7ia/1vMs48UaQwEflGRH4Vke0isiH44Ng/nvtU1aaqOi2e+8gmIhVF5EERWRO8z69EZICISCL2n0c8HUVkXeRzqvqAql4Zp/2JiNwoIotF5BcRWScir4vIn+Kxv6ISkXtF5D/F2YaqvqyqnWLY1++SYyL/JksrTxSp7xxV3R84FmgB3B5yPIUmIuXyWfQ6cCrQBagK9AL6AMPiEIOISLL9PwwDbgJuBP4ANALGAmeV9I6i/A7iLsx9uxipqt9S9AZ8A5wW8fgR4L2Ix22Bj4EfgUVAx4hlfwD+BXwLbAXGRiw7G1gYvO5joFnufQKHAr8Cf4hY1gLYDJQPHv8fsCzY/iSgfsS6ClwHfAWsyuO9nQpkAnVzPd8G2AscGTyeBjwIzAF+Bt7JFVO0YzANuB+YGbyXI4HLg5i3ASuBq4N1qwTrZAHbg9uhwL3Af4J1Dgve12XAmuBY3Bmxv8rAi8HxWAb8FViXz++2YfA+W0f5/Y8ChgPvBfF+AhwRsXwYsDY4LvOBEyOW3Qu8AfwnWH4l0BqYFRyr74B/AhUiXtMU+B/wA/A9cAfQGdgF7A6OyaJg3erA88F21gODgbLBst7BMX8M2BIs6w3MCJZLsGxjENvnwDHYl4Tdwf62A+/m/j8AygZxfR0ck/nk+hvyWxE+a8IOwG/F+OXt+w9SJ/iHGhY8rh38E3bBzhxPDx4fGCx/D3gVOAAoD3QInm8R/IO2Cf7pLgv2UzGPfX4AXBURzxDgmeB+V2AF0BgoB9wFfByxrgYfOn8AKufx3h4CPsznfa8m5wN8WvBBdAz2Yf4mOR/cBR2DadgHetMgxvLYt/Ujgg+rDsAOoGWwfkdyfbCTd6J4DksKzYGdQOPI9xQc8zrAZ7m3F7Hda4DVBfz+RwXvp3UQ/8vAmIjlPYGawbL+wAagUkTcu4HzgmNTGWiFJdZywXtZBtwcrF8V+9DvD1QKHrfJfQwi9v028GzwOzkIS+TZv7PewB7ghmBfldk3UZyBfcDXCH4PjYFDIt7z4Cj/BwOw/4Ojgtc2B2qG/b+a6rfQA/BbMX559g+yHfvmpMD7QI1g2W3AS7nWn4R98B+CfTM+II9tPg38Pddzy8lJJJH/lFcCHwT3Bfv2elLweAJwRcQ2ymAfuvWDxwqcEuW9jYz80Mu1bDbBN3Xsw/6hiGVNsG+cZaMdg4jXDirgGI8FbgrudyS2RFEnYvkcoEdwfyVwRsSyK3NvL2LZncDsAmIbBYyMeNwF+CLK+luB5hFxTy9g+zcDbwf3LwYW5LPeb8cgeHwwliArRzx3MTA1uN8bWJNrG73JSRSnAF9iSatMHu85WqJYDnSNx/9bab4l2zVZV3jnqWpV7EPsaKBW8Hx94EIR+TH7BpyAJYm6wA+qujWP7dUH+ud6XV3sMktubwLtROQQ4CQs+XwUsZ1hEdv4AUsmtSNevzbK+9ocxJqXQ4LleW1nNXZmUIvoxyDPGETkTBGZLSI/BOt3IeeYxmpDxP0dQHYHg0Nz7S/a+99C/u8/ln0hIreKyDIR+Sl4L9XZ973kfu+NROS/QceIn4EHItavi13OiUV97HfwXcRxfxY7s8hz35FU9QPsstdwYKOIjBCRajHuuzBxuhh5okgTqvoh9m3r0eCptdi36RoRtyqq+lCw7A8iUiOPTa0F7s/1uv1UdXQe+9wKTAYuAi7BzgA0YjtX59pOZVX9OHITUd7SFKCNiNSNfFJE2mAfBh9EPB25Tj3sksrmAo7B72IQkYpY8nsUOFhVawDjsQRXULyx+A675JRX3Lm9D9QRkYyi7EhETsTaQLpjZ441gJ/IeS/w+/fzNPAF0FBVq2HX+rPXXwscns/ucm9nLXZGUSviuFdT1aZRXrPvBlWfUNVW2BliI+ySUoGvC/Z9RAHruELyRJFeHgdOF5HmWCPlOSJyhoiUFZFKQffOOqr6HXZp6CkROUBEyovIScE2ngOuEZE2QU+gKiJylohUzWefrwCXAhcE97M9A9wuIk0BRKS6iFwY6xtR1SnYh+WbItI0eA9tg/f1tKp+FbF6TxFpIiL7AYOAN1R1b7RjkM9uKwAVgU3AHhE5E4jssvk9UFNEqsf6PnJ5DTsmB4hIbeD6/FYM3t9TwOgg5gpB/D1EZGAM+6qKtQNsAsqJyN+Agr6VV8Uaj7eLyNHAtRHL/gscIiI3B92WqwZJG+y4HJbdayz4+5oM/ENEqolIGRE5QkQ6xBA3InJc8PdXHvgF69SQFbGv/BIW2CXLv4tIw+Dvt5mI1Ixlvy5/nijSiKpuAv4N/E1V12INyndgHxZrsW9l2b/zXtg37y+wxuubg23MA67CTv23Yg3SvaPsdhzWQ2eDqi6KiOVt4GFgTHAZYzFwZiHfUjdgKjARa4v5D9aT5oZc672EnU1twBpabwxiKOgY7ENVtwWvfQ1775cE7y97+RfAaGBlcEklr8tx0QwC1gGrsDOmN7Bv3vm5kZxLMD9il1T+DLwbw74mYcftS+xyXCbRL3UB3Iq9523YF4ZXsxcEx+Z04BzsOH8FnBwsfj34uUVEPg3uX4ol3qXYsXyD2C6lgSW054LXrcYuww0Jlj0PNAmO/9g8XjsU+/1NxpLe81hjuSsGyblS4FzqEZFpWENqKKOji0NErsUaumP6pu1cWPyMwrkEEZFDROT44FLMUVhX07fDjsu5gsQtUYjICyKyUUQW57NcROQJEVkhIp+JSMt4xeJckqiA9f7ZhjXGv4O1QziX1OJ26SloHN0O/FtVj8ljeRfsWnMXbHDXMFVtk3s955xz4YrbGYWqTsf6zuenK5ZEVFVnAzWC/vjOOeeSSJjFuGqzby+MdcFz3+VeUUT6YHVeqFKlSqujjz46IQE651xY9uyBvXvzXvbNN7B9e2zbqcdqavAjn7Fns6oeWJRYUqJqo6qOAEYAZGRk6Lx580KOyDnn4uehh+D2GOpAf/ghHJ7XqJLsJgURqvz7acps2UiNofeuLmo8YSaK9ew7MrVO8JxzziW9zEyYOxeysvJfZ/hwmDULypYt3LZXBx/p/fpB8+a/X16mDHTuDLXyKi6zfj30vRYuugj+8he4Ixg3OfTewgURIcxEMQ64XkTGYI3ZPwUjOp1zLql89x0MGmTJIduoUbG//rLLCre/smUtSTRtWvC6v1GFkSPh1lth9244q+SmLYlbohCR0Vihulpis4LdgxUKQ1WfwWrodMFG/u7A5gFwzrmksHEjTJ4MvXrlPFeuHBwajMevXRsqV4YRI6Jv5+ij4ZB4d9P5+mu46iqYOhVOPhmeew6OKLmSV3FLFKp6cQHLsyeucc65Ypk1C+69N//G36J4//2c+wceCHffDddfD+FMxFuAzz+H+fMta115ZYkHmRKN2c45F83Eifbt//jjS26b7dtD/fpw//1w2GFJmCAWL4ZPP4VLL4XzzoOVK6FmfOofeqJwzpWYlSvtkk2kjz6yRt0KFeL3Ybs5mJ1kxoz4bD+p7NoFDzxgt4MPhu7doVKluCUJ8EThnMtl4UJ49tmcHpax2rYNXnkl/+XnnWefZ/HSpEn8tp00PvkErrgCliyBnj3hscfie1ADniicKyVmzYK1wRBXVejRw7pZVqiw73rZPXsOPrhw29+7F6pVgxtugBNO2HdZ7drwpz8VLW4XWL8eTjzRfjH//W+J9moqiCcK55LM3r2wNa9JavMwbx488UTBl3R27YIpU37/fM2acHke/Q1btLBE4pLAl19Co0aWbV99FU491TJyAnmicC7J9OwJY8YU7jWtWkVPFqo2cOuGG6BdO3uubFn7/Em6RlpnfvwR/vpXGxsxbRqcdBL8+c+hhOKJwrmQqMLSpfZtP9vYsZYkGjWyD/VYHHEEnFnYuQNdchs3Dq69FjZsgAED4LjjQg3HE4VzIXn9dauykJe//906s7hS6Mor4fnnrVHnnXcgIyPsiDxROJdIw4fDnXfa/Z3BbNn/+hcccEDOOg0blpIePC5HRBE/MjJsAMdtt/2+p0FIPFE4lyCZmTB7tjVWX3GFPXfIIVYHyNsJSrG1a+Gaa6z3QK9edj/JeKJwrpCmT4fPPivca1autC7vAA0awOOPl3xcLsVkZdmAldtus28PITVUx8IThSuVVGHoUHj55cKXgC7OdCiXXgq9exf99S5NfPWVtUVMnw6nnWY1mho0CDuqfHmicKXKxIlWYHPcOPjiC3uuS5fCbaNzZ/uwP/XUwr2uYkWoWrVwr3FpaulSOy194QX7Y0rya4+eKFxa2rnT6v7s3m2PP/oInnzSykyAjUgGazNo0yacGF0ps2iR1Ue57DLo2tWuR0b2YkhinihcWlG15PDCC9C37++X9+xpDckdOyY8NFda7dwJgwfb/KaHHGJ9oitVSpkkAZ4oXBrYvdvGJPzyi3UYiZya8oMPbHIZgIMOymd+YefiZdYs+2aybJk1UA0dmpAifiXNE4VLOVu2WHUDsM4ixx0HP/+cs7xKFbjjDuuKfvLJ4cToHOvXQ4cO8Mc/wvjxKT183hOFS2qqNkgte46Dn3+GYcPyXnfJEqhe3c7us9sgnEu4ZcugcWMr4vfaa9brIcV7MXiicElhxw6YM2ffORCGDLFZy7KntxTJWd67N5xyit0vXx7OOcfOJJwLzdat0L+/DbWfPt1Kgp93XthRlQhPFC5Ujz5qMzq++GL+61xzjc1XnD2pvXNJ5+23rffEpk1w++2hF/EraZ4oXMLt2GFzrkyblvNc3bpWYn/48H3XbdoUatVKaHjOFc7//Z+dRRx7LLz3HrRsGXZEJc4ThSsRGzbAnj35L3/vPSufXaaM9UTKdu+9dhmpfv14R+hcCYos4te2rVVyvPVWuw6ahjxRuGJ58UV45BEbaBqLE06A44+3ophvv22Nz86llNWr4eqr4ZJLrMtrnz5hRxR3nihczFavtt5+5crZmcG2bXYmke2ZZ6LXTWrWDFq3jn+czsVFVhY8/TQMHGhnFBdeGHZECeOJwsWsfXv49lsbwJbdmaNcORuz0KiRd0l1aWz5civiN2MGdOpkVV8POyzsqBLGE4Xbx65dMGGCzZ2wfbv9b4AVtNu50ybUWbgwbS/FOpe35cttoM6oUXa5KcmL+JU0TxSl3KpV0K9fzmxr77+/7xzOAMccY72URKxWkicJVyosWGDfii6/HM4914r41agRdlSh8ERRiqlaz75p02x63kqVrB1B1c6s99vPziQaNCh1X6BcaZaZCYMGWS+N2rXh4ovtn6OUJgnwRFFq/fwzHHVUTmP09Oml+v/AOTNzphXxW77cziT+8Y+ULOJX0jxRlBLvvgv/+1/O4yefzLm/erUnCedYv96qSNauDZMmWaO1AzxRlApPPgk33mj3s0vg778/tGhhRS333z+82JwL3dKl1kujdm14801LFv5PsQ/v0JjmFi+2AaNgs7z98IPdtm2zy03+/+BKrR9+sLIATZvaPwNYdUn/p/gdP6NIY998Y43U4FN+OrePN9+E666zyU3uvNNHghbAE0Wa2rbNejCBfWnyJOFcoHdvqz3TsiVMnGjF/FxUnijSwLx58Oqr+z736KM59x95JLHxOJd0Iov4tW9vEwv172+lBVyB4nqURKQzMAwoC4xU1YdyLa8HvAjUCNYZqKrj4xlTuti9G9q1gzVrrAQ+2LiHbOXK2VnExIl+ydWVcqtWWeG+nj3hsstKRRG/kha3xmwRKQsMB84EmgAXi0iTXKvdBbymqi2AHsBT8YonFe3dayOm87pt3gzz51uNpWuvtTOKX37Jue3ebWVpPEm4UmvvXnjiCSstMHv2vtMnukKJ5xlFa2CFqq4EEJExQFcgsiC1AtWC+9WBb+MYT0qZODG2udgvucQm1nLORVi2zAbOzZpl/0jPPAP16oUdVcqKZ6KoDayNeLwOyN2kei8wWURuAKoAp+W1IRHpA/QBqFcKftm7duUkiQ4d4Iwz8l6vfHno3j1xcTmXMlassNHVL70Ef/mL16ApprBbci4GRqnqP0SkHfCSiByjqlmRK6nqCGAEQEZGRtqeP/70E/zzn3DXXfa4d2+bYdE5F4P582HRIitgds451jZRrVrBr3MFiueAu/VA3YjHdYLnIl0BvAagqrOASkCpnSH50UdzkkT9+t5bybmY/PqrTSbUpg38/e9W1A88SZSgeCaKuUBDEWkgIhWwxupxudZZA5wKICKNsUSxKY4xJa1vv4XBg+3+mjU2WO7AA0MNybnkN306NG8ODz9sp+ALFngRvziI26UnVd0jItcDk7Cury+o6hIRGQTMU9VxQH/gORG5BWvY7q1aOrsmvP++/Rw4EOrWjb6ucw4r4nfqqfYPM2WK3XdxEdc2imBMxPhcz/0t4v5S4Ph4xpDMtm61WeRGjrTy9wCnnBJuTM4lvc8/t9o0tWvD229bEb8qVcKOKq2F3ZhdKkyfDh9+uO9z331n87RHeuklOP30xMXlXErZvBluuQX+8x/7hzrpJDj77LCjKhU8UcTZjh1w2mk2AC4vffpYPbITTrCJhJxzuajC66/D9dfbafg993jxsgTzRBEnmZlw9905NZcuughefnnfdUSgjBd6dy66yy6z0+2MDGvMyy6J7BLGE0UJe/RRq1q8a1fOc40bw/DhULZseHE5l1Iii/h16GClkG++2Yv4hcSPegmaPRsGDLD6Sv36WfvaLbd4O5tzhbJyJVx1lRXxu/xyK8XhQuUXPkrI/fdbNVewgaEPPmiD5zxJOBejvXvh8cft0tLcuX5dNon4GUUxvfACPPAAfP21PX7kETurcM4VwtKl9g3rk0/grLOsiF+dOmFH5QKeKIrpf/+DDRvgwgutbaJ587Ajci4FrVpl37ZeeQV69PAifknGE0URZWVZB4y1a23cz2uvhR2Rcylm7lxYuNDaI846y9omqlYNOyqXB78IWASPP25VAzp1gpkz4YADwo7IuRSyYwfceiu0bWuNedlF/DxJJC1PFEXw+OP2t964MUyeDJMmhR2Rcyli2jTr6vqPf9iZhBfxSwl+6akQsrKsaN/q1TYGaNSosCNyLoWsW2c1aurXhw8+sBpNLiX4GUUhPPMMDBli9y++ONxYnEsZixbZzzp14J134LPPPEmkGE8UhfDDD/Zz2bL8pyd1zgU2bbJJ3Y89NqcqZpcusN9+4cblCs0vPRVg50544gmYNw+WLLHnjjwy3JicS2qqMGYM3Hijze973305o1FdSvJEEcWLL9qkWdmOPhq6dvWaTc5F1auXVcBs0waefx6aNg07IldMMScKEdlPVXfEM5hk0a8fzJplYyQAHnoIunXzMwnn8pWVZYPkRKz9oVUrO6Pwb1VpocBEISLtgZHA/kA9EWkOXK2qfeMdXKKowrBhdkkVbEKhWrXsi1D37nDbbeHG51xSW7HCurr26mVlOLyIX9qJ5YziMeAMYByAqi4SkZPiGlWCvf++VXktU8ZuInDHHXDttWFH5lwS27PHBhXdfTdUrOgJIo3FdOlJVdfKvrVX9sYnnMR7+204/3y7/9Zb1gbhnCvA4sVWAnzePPuneeopOPTQsKNycRJLolgbXH5SESkP3AQsi29YiTNsmP287TY455xwY3EuZaxZYyNPx4yx67NexC+txZIorgGGAbWB9cBkIG3aJ8Am0HroobCjcC7JffKJDZ7r08fGQ6xcabN0ubQXy4C7o1T1L6p6sKoepKo9gcbxDsw5lyR++cW6ArZrZxOu7Nxpz3uSKDViSRRPxvhcysnMtEuszrl8fPCBFfF77DG45hr49FNruHalSr6XnkSkHdAeOFBE+kUsqgakfOfo77+HQw6xrrH+xci5PKxbZ7VqGjSwEhwnpVVnR1cI0dooKmBjJ8oBkYXifwYuiGdQiTBggCWJChVsOlPnXGDBAmjRwor4vfuuNeJVrhx2VC5EoqrRVxCpr6qrExRPgTIyMnReMa8XrVwJRxxh9zduhAMPLIHAnEt1339vo6lfe83mjejQIeyIXAkSkfmqmlGU18bS62mHiAwBmgK/zTCiqqcUZYfJIHtCrSee8CThHKpWm+mmm2D7dhg8GNq3Dzsql0Riacx+GfgCaADcB3wDzI1jTAlz8MFhR+BcErjkEiu/cdRRNof1nXdC+fJhR+WSSCxnFDVV9XkRuUlVPwQ+FJGUThTPPht2BM6FLLKIX6dO1vX1uuu8iJ/LUyxnFLuDn9+JyFki0gL4QxxjiqtvvrFLTmBfoJwrdb780iq8ZvfiuPxyr/TqoorljGKwiFQH+mPjJ6oBN8c1qjjq3t1+PvQQNG8ebizOJdSePTB0KNxzD1Sq5D2ZXMwKTBSq+t/g7k/AyQAicnw8g4qXIUNg7lw4/HC49dawo3EugT77zEqAz58Pf/4zDB9uA4mci0G0AXdlge5YjaeJqrpYRM4G7gAqAy0SE2LJWR108h071s+yXSmzbp3NxPX66zYLlxfxc4WQ7zgKERkF1AXmAG2Ab4EMYKCqjo1p4yKdsYKCZYGRqvq70nsi0h24F1BgkapeEm2bRR1HsXGj9XKqXh1+/LHQL3cu9Xz8sZ1JXHONPf7lF6hSJdyYXGjiNY4iA2imqlkiUgnYAByhqltiDKosMBw4HVgHzBWRcaq6NGKdhsDtwPGqulVEDirKmyjI5s05XWEbNozHHpxLItu3WxfXJ5+0kaWXX271mTxJuCKK1utpl6pmAahqJrAy1iQRaA2sUNWVqroLGAPknhboKmC4qm4N9rOxENuPWfYlp+OOgzlz4rEH55LE5MlwzDGWJK67zov4uRIR7YziaBH5LLgvwBHBYwFUVZsVsO3awNqIx+uwS1iRGgGIyEzs8tS9qjox94ZEpA/QB6BevXoF7Pb3sgeZ/u1vfmnWpbG1a+Gss+wsYvp0OOGEsCNyaSJaokjEnBPlgIZAR6AOMF1E/qSq+7QiqOoIYARYG0Vhd7JrFxx0EJySskVHnIti/nxo1Qrq1oXx4+HEE637q3MlJN9LT6q6Otothm2vxxrDs9UJnou0DhinqrtVdRXwJZY4SpQIXH017LdfSW/ZuRBt2AAXXggZGVYGHOD00z1JuBIXy8jsopoLNBSRBiJSAegBjMu1zljsbAIRqYVdiloZx5icS32q8OKL0KSJlQF/4AEv4ufiKpaR2UWiqntE5HpgEtb+8IKqLhGRQcA8VR0XLOskIkuBvcCAQjaYO1f69OhhpcCPPx5GjoSjjw47IpfmYkoUIlIZqKeqywuzcVUdD4zP9dzfIu4r0C+4xcWSJfYFzLmUFlnEr0sXa4fo2xfKxPOigHOmwL8yETkHWAhMDB4fKyK5LyElpaws+58C+OMfw43FuSL74gubhvT55+3xZZfB9dd7knAJE8tf2r3YmIgfAVR1ITY3RdJ6+WW47z4bhb1mDbRtC9deG3ZUzhXS7t3W/tC8OSxd6pO7u9DEculpt6r+JPsOQEjaizm33AKPP57zuGxZeOUVHz/hUszChTaieuFCuOACG0Dnp8UuJLEkiiUicglQNii5cSPwcXzDKropU+znkiXQOBgJ4knCpZwNG+z25ptw/vlhR+NKuVguPd2AzZe9E3gFKzeelPNRPPooLF5sxTGbNMlp+3MuJcyYAU89Zfc7d4avv/Yk4ZJCLIniaFW9U1WPC253BbWfksrMmTBggN2//fZwY3GuULZts8bpE0+066Y7d9rzPkLUJYlYEsU/RGSZiPxdRI6Je0RFsHx5Tlmbm2+2agbOpYRJk6yI31NPwU03eRE/l5QKTBSqejI2s90m4FkR+VxE7op7ZIWwMag5e8st8Nhj4cbiXMzWroWzz7Yzhxkz7GzCeza5JBRTR2xV3aCqTwDXYGMq/lbAS0Jx1llhR+BcAVRzat3XrQsTJsCCBV6CwyW1WAbcNRaRe0Xkc+BJrMdTnbhH5ly6+e4762nRpk1OEb/TTvMifi7pxdI99gXgVeAMVf02zvE4l35UYdQo6NcPMjPh4YetTpNzKaLARKGq7RIRiHNpq3t3eOMN69U0ciQ0ahR2RM4VSr6JQkReU9XuwSWnyJHYsc5wlxBZWdCrV9hROJfL3r02iKdMGTjnHJs16+qrvT6TS0nRzihuCn6enYhAiurXX3PmxG7ZMtxYnANg2TK44gorwXHVVXDppWFH5FyxRJvh7rvgbt88Zrfrm5jwYvfII3DAAWFH4Uq13bth8GA49lgb3FO9etgROVciYjkPPj2P584s6UCcS2kLFtiUpHffDX/+s51VdO8edlTOlYhobRTXYmcOh4vIZxGLqgIz4x2Ycynl++9h82YYOxa6dg07GudKVLQ2ileACcCDwMCI57ep6g9xjcq5VDB9Onz+OVx3nRXxW7ECKlcOOyrnSly0S0+qqt8A1wHbIm6IyB/iH5pzSernn20a0g4d4Ikncor4eZJwaaqgM4qzgflY99jIgt0KHB7HuGK2dm3YEbhSZfx46+b67bc2gG7QIC/i59JevolCVc8Ofib1tKfZ7YXVqoUbhysF1q619oejjrIBdG3ahB2RcwkRS62n40WkSnC/p4gMFZF68Q8tNr/+CkccYd3WnStxqjB7tt2vWxcmT7ZS4J4kXCkSS/fYp4EdItIc6A98DbwU16gKoUwZOO44KBdL1SrnCuPbb+G886Bdu5wifiefDBUqhBuXcwkWS6LYo6oKdAX+qarDsS6yzqUnVavJ1KSJnUE8+njOlWcAABm3SURBVKgX8XOlWiyJYpuI3A70At4TkTJA+fiGFZtnnoEvvww7Cpd2LrjASm8ce6x1f+3f309ZXakWS6K4CNgJ/J+qbsDmohgS16hilH01oE+fcONwaWDvXqswCXa56Zln4IMP4Mgjw43LuSQQy1SoG4CXgeoicjaQqar/jntkMWrUyC4bO1dkixfbpaXnn7fHvXp5pVfnIsTS66k7MAe4EOgOfCIiF8Q7MOfibtcuuO8+Kzv89ddeVdK5fMRy4fVO4DhV3QggIgcCU4A34hmYc3E1fz707m1nE5dcAo8/DgceGHZUziWlWBJFmewkEdhCbG0bziWvLVvgxx/h3Xfh7KSecsW50MWSKCaKyCRgdPD4ImB8/EJyLk6mTrVeTDfeCJ06wVdfQaVKYUflXNKLpTF7APAs0Cy4jVDV2+IdmHMl5qefrHH6lFPg6adzivh5knAuJtHmo2gIPAocAXwO3Kqq6xMVmHMl4t134ZprYMMGuPVWa7z2In7OFUq0M4oXgP8C3bAKsk8mJCLnSsratdCtG9SsafWahgyB/fYLOyrnUk60NoqqqvpccH+5iHyaiICcKxZVmDUL2rfPKeLXvr3XZ3KuGKKdUVQSkRYi0lJEWgKVcz0ukIh0FpHlIrJCRAZGWa+biKiIZBT2DTj3m3Xr4NxzbfBc9rD9jh09SThXTNHOKL4DhkY83hDxWIFTom1YRMoCw4HTgXXAXBEZp6pLc61XFbgJ+KQwgf/6K0yZAjVqFOZVLi1lZcFzz8GAAbBnDwwdCiecEHZUzqWNaBMXFbcwRmtghaquBBCRMVgF2qW51vs78DAwoDAbf+EFm8u+Tp1iRulSX7duMHas9Wp67jk4PCkmX3QubcRz4FxtIHKi0nXBc78JLmHVVdX3om1IRPqIyDwRmbdp0yYAduywZe++W4IRu9SxZ09OEb9u3SxBTJniScK5OAhthHVQrnwoNhlSVKo6QlUzVDXjwFxlFrw8Tyn02Wc2mdBzQV+Lnj3hyitBJPrrnHNFEs9EsR6oG/G4TvBctqrAMcA0EfkGaAuM8wZtl6+dO+Gee6BVK1i92mszOZcgsVSPlWCu7L8Fj+uJSOsYtj0XaCgiDUSkAtADGJe9UFV/UtVaqnqYqh4GzAbOVdV5BW1YFWbOjCEClz7mzrUqr4MGwcUXw7JlcP75YUflXKkQyxnFU0A74OLg8TasN1NUqroHuB6YBCwDXlPVJSIySETOLWK8gJXpeecdu18+Kebac3G3dSts3w7jx8O//22D6JxzCSE2HXaUFUQ+VdWWIrJAVVsEzy1S1eYJiTCXFi0ydOFCO+mYNQvatg0jCpcQH3xgRfxuuske79zp5TecKyIRma+qRbq0H8sZxe5gTIQGOzsQyCrKzkrS4497kkhbP/5oc1afeio8+2xOET9PEs6FIpZE8QTwNnCQiNwPzAAeiGtUUfz0U1h7dgnxzjvQpIkNlPnrX22CIU8QzoWqwPkoVPVlEZkPnAoIcJ6qLot7ZPlYt85+NmwYVgQubtasgQsvhMaNYdw4yPAOcM4lgwIThYjUA3YA70Y+p6pr4hlY/vHApZdCly5h7N2VOFWYMQNOPBHq1bNBc23ben0m55JILDPcvYe1TwhQCWgALAeaxjEuVxqsWWNzRUyYANOmQYcOcNJJYUflnMsllktPf4p8HJTd6Bu3iAqwa1dYe3YlJisLnnkGbrvNziieeMKL+DmXxGI5o9iHqn4qIm3iEUysunYNc++u2M4/3xqtTz8dRoyAww4LOyLnXBSxtFH0i3hYBmgJfBu3iApQqZIPyE1Je/ZAmTJ2u+giy/a9e3t9JudSQCzdY6tG3CpibRb+nd7FbtEiaNPGzh7ASnBcfrknCedSRNQzimCgXVVVvTVB8bh0kpkJgwfDww/DH/4Af/xj2BE554og30QhIuVUdY+IHJ/IgFyamDMHLrsMvvjCfg4dasnCOZdyop1RzMHaIxaKyDjgdeCX7IWq+lacY3Op7Oefbb7aiRPhjDPCjsY5Vwyx9HqqBGzB5sjOHk+hgCcKt6/Jk2HJErjlFjjtNFi+3MtvOJcGoiWKg4IeT4vJSRDZopecdaXL1q3Qrx+MGgVNm0LfvpYgPEk4lxai9XoqC+wf3KpG3M++OQdvvWVF/F56CW6/HebN8wThXJqJdkbxnaoOSlgkLvWsWQM9esAxx9iEQi1ahB2Rcy4Oop1ReCd393uq8OGHdr9ePZtc6JNPPEk4l8aiJYpTExaFSw2rV8OZZ0LHjjnJ4oQTfD5a59JcvolCVX9IZCAuiWVlwT//aQ3VM2bAk09aWXDnXKlQ6KKArhQ67zx4910bD/Hss1C/ftgROecSyBOFy9vu3VC2rBXxu/hiuOAC6NXL6zM5VwrFUhTQlTaffgqtW9ucEWCJ4tJLPUk4V0p5onA5fv3VxkK0bg0bNkDdumFH5JxLAn7pyZnZs61435dfwv/9Hzz6KBxwQNhROeeSgCcKZ375xdol/vc/q9PknHMBTxSl2cSJVsSvf3849VQrCV6hQthROeeSjLdRlEZbtthlpjPPhBdfhF277HlPEs65PHiiKE1U4Y03rIjfK6/AXXfB3LmeIJxzUfmlp9JkzRq45BJo1szmjmjePOyInHMpwM8o0p2qFe4DG1E9bZr1cPIk4ZyLkSeKdLZqFXTqZA3V2UX82reHcn4i6ZyLnSeKdLR3LwwbZvNEfPIJPP20F/FzzhWZf7VMR127wnvvQZcuVobDR1g754rBE0W6iCzi16uX1We65BKvz+ScK7a4XnoSkc4islxEVojIwDyW9xORpSLymYi8LyJev7oo5s2DjAy7xARw0UXwl794knDOlYi4JQoRKQsMB84EmgAXi0iTXKstADJUtRnwBvBIvOJJS7/+CrfdBm3awKZNPk+Ecy4u4nlG0RpYoaorVXUXMAboGrmCqk5V1R3Bw9lAnTjGk15mzbIuro88YkX8li6Fs88OOyrnXBqKZxtFbWBtxON1QJso618BTMhrgYj0AfoAlC/v/f8BO5vIyoIpU6z7q3POxUlSNGaLSE8gA+iQ13JVHQGMAKhcOUMTGFpyGT/eivgNGACnnALLlkH58mFH5ZxLc/G89LQeiOyXWSd4bh8ichpwJ3Cuqu6MYzypa/Nm6NkTzjoLXn45p4ifJwnnXALEM1HMBRqKSAMRqQD0AMZFriAiLYBnsSSxMY6xpCZVGDMGGjeG116De+6BOXO8iJ9zLqHidulJVfeIyPXAJKAs8IKqLhGRQcA8VR0HDAH2B14X68q5RlXPjVdMKWfNGisH3rw5PP88/OlPYUfknCuFRDW1LvlXrpyhv/46L+ww4kcV3n8/Z5a52bPhuONsMJ1zzhWRiMxX1YyivNZrPSWTr7+2Hkynn55TxK9tW08SzrlQeaJIBnv3wtChdmlp/nx49lkv4uecSxpJ0T221DvnHJgwwQbMPf001PFxh8655OGJIiy7dtm8EGXKQO/eVsivRw+vz+ScSzp+6SkMc+ZAq1bw1FP2uHt3q/bqScI5l4Q8USTSjh3Qvz+0awdbt8IRR4QdkXPOFcgvPSXKjBk2JmLlSrj6anj4YahePeyonHOuQJ4oEiV7YqGpU6Fjx7Cjcc65mHmiiKd337XCfX/9K5x8spUCL+eH3DmXWryNIh42bbJpSM89F0aPzini50nCOZeCPFGUJFV45RUr4vfGGzBoEHzyiRfxc86lNP+KW5LWrIHLL4cWLayIX9OmYUfknHPF5mcUxZWVBZMm2f369eGjj2DmTE8Szrm04YmiOL76ymaa69wZpk+351q39iJ+zrm04omiKPbsgSFDoFkzWLjQLjN5ET/nXJryNoqiOPtsu9zUtauV4Tj00LAjci4p7d69m3Xr1pGZmRl2KKVGpUqVqFOnDuVLcKpkn7goVjt32hzVZcpYj6asLLjwQq/P5FwUq1atomrVqtSsWRPx/5W4U1W2bNnCtm3baNCgwT7LfOKieJs9G1q2hOHD7fEFF1ghP//Ddy6qzMxMTxIJJCLUrFmzxM/gPFFE88svcMst0L49bNsGDRuGHZFzKceTRGLF43h7G0V+PvrIivitWgV9+8KDD0K1amFH5ZxzCednFPnZs8faJD780C45eZJwLmWNHTsWEeGLL7747blp06Zx9tln77Ne7969eeONNwBriB84cCANGzakZcuWtGvXjgkTJhQ7lgcffJAjjzySo446iknZY7Byef/992nZsiXHHnssJ5xwAitWrABgzZo1nHzyybRo0YJmzZoxfvz4YscTC08UkcaOtTMHsCJ+S5bASSeFG5NzrthGjx7NCSecwOjRo2N+zd133813333H4sWL+fTTTxk7dizbtm0rVhxLly5lzJgxLFmyhIkTJ9K3b1/27t37u/WuvfZaXn75ZRYuXMgll1zC4MGDARg8eDDdu3dnwYIFjBkzhr59+xYrnlj5pSeA77+HG26A11+3Ruv+/a0+kxfxc67E3HyzDTsqScceC48/Hn2d7du3M2PGDKZOnco555zDfffdV+B2d+zYwXPPPceqVauoWLEiAAcffDDdu3cvVrzvvPMOPXr0oGLFijRo0IAjjzySOXPm0K5du33WExF+/vlnAH766ScODbrg5/d8vJXuT0JV+M9/7C94+3a4/34YMMAuOTnn0sI777xD586dadSoETVr1mT+/Pm0atUq6mtWrFhBvXr1qBbDJedbbrmFqVOn/u75Hj16MHDgwH2eW79+PW3btv3tcZ06dVi/fv3vXjty5Ei6dOlC5cqVqVatGrNnzwbg3nvvpVOnTjz55JP88ssvTJkypcD4SkLpThRr1sCVV0JGho2uPvrosCNyLm0V9M0/XkaPHs1NN90E2If36NGjadWqVb69gwrba+ixxx4rdox5bXP8+PG0adOGIUOG0K9fP0aOHMno0aPp3bs3/fv3Z9asWfTq1YvFixdTpkx8WxFKX6LILuJ35plWxG/mTKv26vWZnEs7P/zwAx988AGff/45IsLevXsREYYMGULNmjXZunXr79avVasWRx55JGvWrOHnn38u8KyiMGcUtWvXZu3atb89XrduHbVr195nnU2bNrFo0SLatGkDwEUXXUTnzp0BeP7555k4cSIA7dq1IzMzk82bN3PQQQfFeESKSFVT6lapUistsuXLVU88URVUp00r+nacczFZunRpqPt/9tlntU+fPvs8d9JJJ+mHH36omZmZethhh/0W4zfffKP16tXTH3/8UVVVBwwYoL1799adO3eqqurGjRv1tddeK1Y8ixcv1mbNmmlmZqauXLlSGzRooHv27Nlnnd27d2vNmjV1+fLlqqo6cuRIPf/881VVtXPnzvqvf/1LVe3YHnLIIZqVlfW7/eR13IF5WsTP3dA/+At7K1Ki2L1b9aGHVCtWVK1RQ/Vf/1LN4+A650pW2ImiY8eOOmHChH2eGzZsmF5zzTWqqjpjxgxt06aNNm/eXDMyMnTy5Mm/rbdz504dMGCAHnHEEdq0aVNt3bq1Tpw4sdgxDR48WA8//HBt1KiRjh8//rfnzzzzTF2/fr2qqr711lt6zDHHaLNmzbRDhw769ddfq6rqkiVLtH379tqsWTNt3ry5Tpo0Kc99lHSiKB21ns44AyZPhvPPtzERf/xjfIJzzu1j2bJlNG7cOOwwSp28jntxaj2lbxtFZqb1XipbFvr0sVu3bmFH5ZxzKSc9B9zNnGkdrLOL+HXr5knCOeeKKL0SxfbtcOONNolQZib4Ka9zoUu1y9upLh7HO30SxYcfwjHHwD//CddfD4sXw+mnhx2Vc6VapUqV2LJliyeLBNFgPopKlSqV6HbTq41iv/2s6uvxx4cdiXMOG3m8bt06Nm3aFHYopUb2DHclKbV7Pb31FnzxBdxxhz3eu9cHzjnnXB6SdoY7EeksIstFZIWIDMxjeUUReTVY/omIHBbThjdssFnmunWDt9+GXbvseU8SzjlX4uKWKESkLDAcOBNoAlwsIk1yrXYFsFVVjwQeAx4uaLs19m6xRur//tdKgn/8sVV6dc45FxfxPKNoDaxQ1ZWqugsYA3TNtU5X4MXg/hvAqVJARa5Dd6+2RutFi2DgQK/06pxzcRbPxuzawNqIx+uANvmto6p7ROQnoCawOXIlEekD9Ake7pQZMxZ7pVcAapHrWJVifixy+LHI4ccix1FFfWFK9HpS1RHACAARmVfUBpl048cihx+LHH4scvixyCEihax9lCOel57WA3UjHtcJnstzHREpB1QHtsQxJuecc4UUz0QxF2goIg1EpALQAxiXa51xwGXB/QuADzTV+us651yai9ulp6DN4XpgElAWeEFVl4jIIKzc7TjgeeAlEVkB/IAlk4KMiFfMKciPRQ4/Fjn8WOTwY5GjyMci5QbcOeecS6z0qfXknHMuLjxROOeciyppE0Xcyn+koBiORT8RWSoin4nI+yJSP4w4E6GgYxGxXjcRURFJ266RsRwLEeke/G0sEZFXEh1josTwP1JPRKaKyILg/6RLGHHGm4i8ICIbRWRxPstFRJ4IjtNnItIypg0XdQ7VeN6wxu+vgcOBCsAioEmudfoCzwT3ewCvhh13iMfiZGC/4P61pflYBOtVBaYDs4GMsOMO8e+iIbAAOCB4fFDYcYd4LEYA1wb3mwDfhB13nI7FSUBLYHE+y7sAEwAB2gKfxLLdZD2jiEv5jxRV4LFQ1amquiN4OBsbs5KOYvm7APg7VjcsM5HBJVgsx+IqYLiqbgVQ1Y0JjjFRYjkWClQL7lcHvk1gfAmjqtOxHqT56Qr8W81soIaIHFLQdpM1UeRV/qN2fuuo6h4gu/xHuonlWES6AvvGkI4KPBbBqXRdVX0vkYGFIJa/i0ZAIxGZKSKzRaRzwqJLrFiOxb1ATxFZB4wHbkhMaEmnsJ8nQIqU8HCxEZGeQAbQIexYwiAiZYChQO+QQ0kW5bDLTx2xs8zpIvInVf0x1KjCcTEwSlX/ISLtsPFbx6hqVtiBpYJkPaPw8h85YjkWiMhpwJ3Auaq6M0GxJVpBx6IqcAwwTUS+wa7BjkvTBu1Y/i7WAeNUdbeqrgK+xBJHuonlWFwBvAagqrOASljBwNImps+T3JI1UXj5jxwFHgsRaQE8iyWJdL0ODQUcC1X9SVVrqephqnoY1l5zrqoWuRhaEovlf2QsdjaBiNTCLkWtTGSQCRLLsVgDnAogIo2xRFEa52cdB1wa9H5qC/ykqt8V9KKkvPSk8Sv/kXJiPBZDgP2B14P2/DWqem5oQcdJjMeiVIjxWEwCOonIUmAvMEBV0+6sO8Zj0R94TkRuwRq2e6fjF0sRGY19OagVtMfcA5QHUNVnsPaZLsAKYAdweUzbTcNj5ZxzrgQl66Un55xzScIThXPOuag8UTjnnIvKE4VzzrmoPFE455yLyhOFS0oisldEFkbcDouy7vYS2N8oEVkV7OvTYPRuYbcxUkSaBPfvyLXs4+LGGGwn+7gsFpF3RaRGAesfm66VUl3iePdYl5REZLuq7l/S60bZxijgv6r6hoh0Ah5V1WbF2F6xYypouyLyIvClqt4fZf3eWAXd60s6Fld6+BmFSwkisn8w18anIvK5iPyuaqyIHCIi0yO+cZ8YPN9JRGYFr31dRAr6AJ8OHBm8tl+wrcUicnPwXBUReU9EFgXPXxQ8P01EMkTkIaByEMfLwbLtwc8xInJWRMyjROQCESkrIkNEZG4wT8DVMRyWWQQF3USkdfAeF4jIxyJyVDBKeRBwURDLRUHsL4jInGDdvKrvOrevsOun+81ved2wkcQLg9vbWBWBasGyWtjI0uwz4u3Bz/7AncH9sljtp1rYB3+V4PnbgL/lsb9RwAXB/QuBT4BWwOdAFWzk+xKgBdANeC7itdWDn9MI5r/IjilinewY/wy8GNyvgFXyrAz0Ae4Knq8IzAMa5BHn9oj39zrQOXhcDSgX3D8NeDO43xv4Z8TrHwB6BvdrYPWfqoT9+/Zbct+SsoSHc8Cvqnps9gMRKQ88ICInAVnYN+mDgQ0Rr5kLvBCsO1ZVF4pIB2yimplBeZMK2DfxvAwRkbuwGkBXYLWB3lbVX4IY3gJOBCYC/xCRh7HLVR8V4n1NAIaJSEWgMzBdVX8NLnc1E5ELgvWqYwX8VuV6fWURWRi8/2XA/yLWf1FEGmIlKsrns/9OwLkicmvwuBJQL9iWc3nyROFSxV+AA4FWqrpbrDpspcgVVHV6kEjOAkaJyFBgK/A/Vb04hn0MUNU3sh+IyKl5raSqX4rNe9EFGCwi76vqoFjehKpmisg04AzgImySHbAZx25Q1UkFbOJXVT1WRPbDahtdBzyBTdY0VVX/HDT8T8vn9QJ0U9XlscTrHHgbhUsd1YGNQZI4GfjdvOBic4V/r6rPASOxKSFnA8eLSHabQxURaRTjPj8CzhOR/USkCnbZ6CMRORTYoar/wQoy5jXv8O7gzCYvr2LF2LLPTsA+9K/Nfo2INAr2mSe1GQ1vBPpLTpn97HLRvSNW3YZdgss2CbhBgtMrscrDzkXlicKlipeBDBH5HLgU+CKPdToCi0RkAfZtfZiqbsI+OEeLyGfYZaejY9mhqn6KtV3MwdosRqrqAuBPwJzgEtA9wOA8Xj4C+Cy7MTuXydjkUlPUpu4ES2xLgU9FZDFWNj7qGX8Qy2fYpDyPAA8G7z3ydVOBJtmN2diZR/kgtiXBY+ei8u6xzjnnovIzCuecc1F5onDOOReVJwrnnHNReaJwzjkXlScK55xzUXmicM45F5UnCuecc1H9P93b+X4mzlSlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 在測試集上計算預測機率\n",
    "probs = bert_predict(bert_classifier, val_dataloader)\n",
    "# 評價 Bert 分類器\n",
    "evaluate_roc(probs, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GHiSqBz2P09",
    "outputId": "be8c59a3-a622-4160-d8d3-22550a882179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.637497   |     -      |     -     |   5.92   \n",
      "   1    |   40    |   0.474333   |     -      |     -     |   5.65   \n",
      "   1    |   60    |   0.435349   |     -      |     -     |   5.65   \n",
      "   1    |   80    |   0.463419   |     -      |     -     |   5.65   \n",
      "   1    |   100   |   0.395974   |     -      |     -     |   5.64   \n",
      "   1    |   120   |   0.389625   |     -      |     -     |   5.65   \n",
      "   1    |   140   |   0.369914   |     -      |     -     |   5.64   \n",
      "   1    |   160   |   0.428711   |     -      |     -     |   5.65   \n",
      "   1    |   180   |   0.429731   |     -      |     -     |   5.65   \n",
      "   1    |   200   |   0.387244   |     -      |     -     |   5.65   \n",
      "   1    |   220   |   0.374468   |     -      |     -     |   5.65   \n",
      "   1    |   237   |   0.368318   |     -      |     -     |   4.78   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.311494   |     -      |     -     |   5.92   \n",
      "   2    |   40    |   0.301914   |     -      |     -     |   5.65   \n",
      "   2    |   60    |   0.344424   |     -      |     -     |   5.64   \n",
      "   2    |   80    |   0.306116   |     -      |     -     |   5.64   \n",
      "   2    |   100   |   0.334077   |     -      |     -     |   5.64   \n",
      "   2    |   120   |   0.352777   |     -      |     -     |   5.65   \n",
      "   2    |   140   |   0.320868   |     -      |     -     |   5.65   \n",
      "   2    |   160   |   0.314675   |     -      |     -     |   5.64   \n",
      "   2    |   180   |   0.366367   |     -      |     -     |   5.64   \n",
      "   2    |   200   |   0.327552   |     -      |     -     |   5.65   \n",
      "   2    |   220   |   0.325271   |     -      |     -     |   5.65   \n",
      "   2    |   237   |   0.331172   |     -      |     -     |   4.79   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# 連結訓練集與驗證集\n",
    "full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
    "full_train_sampler = RandomSampler(full_train_data)\n",
    "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n",
    "\n",
    "# 在完整的訓練資料上重新訓練 Bert 分類器\n",
    "set_seed(42)\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "train(bert_classifier, full_train_dataloader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "IPQa8QlO2pPK",
    "outputId": "f859688b-2b26-4e97-b7c4-b46dbb71a448"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>8051</td>\n",
       "      <td>Refugees as citizens - The Hindu http://t.co/G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>425</td>\n",
       "      <td>@5SOStag honestly he could say an apocalypse i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1330</td>\n",
       "      <td>If you bored as shit don't nobody fuck wit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>663</td>\n",
       "      <td>@RealTwanBrown Yesterday I Had A Heat Attack ?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>2930</td>\n",
       "      <td>The Devil Wears Prada is still one of my favou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "2406  8051  Refugees as citizens - The Hindu http://t.co/G...\n",
       "134    425  @5SOStag honestly he could say an apocalypse i...\n",
       "411   1330  If you bored as shit don't nobody fuck wit you...\n",
       "203    663  @RealTwanBrown Yesterday I Had A Heat Attack ?...\n",
       "889   2930  The Devil Wears Prada is still one of my favou..."
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJOuXOEL4ES8",
    "outputId": "488a8d58-4977-446f-c56e-2217ea265c49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# 在測試集推文上執行 `preprocessing_for_bert` 函數\n",
    "print('Tokenizing data...')\n",
    "test_inputs, test_masks = preprocessing_for_bert(test_df['text'])\n",
    "# 宣告測試集的 DataLoader\n",
    "test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63yYRCzf4GYI",
    "outputId": "c8905da3-1bfb-4401-82f8-6669d3b84061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets predicted non-negative:  753\n"
     ]
    }
   ],
   "source": [
    "# 在測試資料上計算最終預測機率\n",
    "probs = bert_predict(bert_classifier, test_dataloader)\n",
    "# 將機率值轉為預測(超過門檻的預測為 1, 否則為 0)\n",
    "threshold = 0.9\n",
    "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
    "# 顯示被判定為\n",
    "print(\"Number of tweets predicted non-negative: \", preds.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlBlZA424dCp"
   },
   "source": [
    "batch_size = 32 D_in, H, D_out = 768, 50, 2\n",
    "Acc: 81.68\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "HkU-6ovb4J5I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "for class.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
