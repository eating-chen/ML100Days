{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSmJJczZo5zp"
   },
   "source": [
    "# 專題（一）：訓練LSTM之歌詞自動填詞器\n",
    "\n",
    "## 專案目標\n",
    "- 目標：使用 LSTM 模型去學習五月天歌詞，並且可以自動填詞來產生歌詞\n",
    "- mayday_lyrics.txt 資料說明：\n",
    "    - 每一行都是一首歌的歌詞\n",
    "    - 除去標點符號並以空白表示間格\n",
    "- 利用 mayday_lyrics.txt 來產生歌詞的序列\n",
    "- 使用 LSTM 模型去學習歌詞的序列\n",
    "- 當我們給定開頭的一段歌詞，例如：”給我一首歌”，就可以用 LSTM 猜下一個字，反覆這個過程就可以自動填詞\n",
    "\n",
    "## 實作提示\n",
    "- STEP1：從 mayday_lyrics.txt 中取出歌詞\n",
    "- STEP2：建立每個字的 Index\n",
    "- STEP3：用 Rolling 的方式打造 LyricsDataset\n",
    "- STEP4：使用 DataLoader 來包裝 LyricsDataset\n",
    "- STEP5：建立 LSTM 模型： inputs > nn.Embedding > nn.LSTM > nn.Dropout > 取最後一個 state > nn.Linear > softmax\n",
    "- STEP6：開始訓練並調整參數\n",
    "- STEP7：進行 Demo，給定 pre_text ，使用模型迭代的預測下一個字產生歌詞\n",
    "- (進階) STEP8：在 Demo 時可以採用依照 Softmax 機率來作隨機採樣，這可以增加隨機性，讓歌詞有更多變化，當然你還可以使用機率閥值來避免太奇怪的字出現\n",
    "\n",
    "## 重要知識點：專題結束後你可以學會\n",
    "- 如何讀取並處理需要 Rolling 的序列資料\n",
    "- 了解如何用 Pytorch 建制一個 LSTM 的模型\n",
    "- 學會如何訓練一個語言模型\n",
    "- 學會如何隨機抽樣自 Softmax 的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hen1MQ1F_cly"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7joX8NEEu90J"
   },
   "outputs": [],
   "source": [
    "lyrics_list = [line.strip() for line in open('mayday_lyrics.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'如果你眼神能夠為我 片刻的降臨 如果你能聽到 心碎的聲音 沈默的守護著你 沈默的等奇跡 沈默的讓自己 像是空氣 大家都吃著聊著笑著 今晚多開心 最角落里的我 笑得多合群 盤底的洋蔥像我 永遠是調味品 偷偷地看著你 偷偷地隱藏著自己 如果你願意一層一層一層的剝開我的心 你會發現你會訝異 你是我最壓抑最深處的秘密 如果你願意一層一層一層的剝開我的心 你會鼻酸你會流淚 只要你能聽到我看到我的全心全意 聽你說你和你的他們 曖昧的空氣 我和我的絕望 裝得很風趣 我就像一顆洋蔥 永遠是配角戲 多希望能與你 有一秒專屬的劇情 如果你願意一層一層一層的剝開我的心 你會發現你會訝異 你是我最壓抑最深處的秘密 如果你願意一層一層一層的剝開我的心 你會鼻酸你會流淚 只要你能聽到我看到我的全心全意 如果你願意一層一層一層的剝開我的心 你會發現你會訝異 你是我最壓抑最深處的秘密 如果你願意一層一層一層的剝開我的心 你會鼻酸你會流淚 只要你能看到我聽到我的全心全意 你會鼻酸你會流淚 只要你能聽到我看到我的全心全意'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_P3Bonv_7FpS"
   },
   "outputs": [],
   "source": [
    "# 建立詞典對照表\n",
    "word2index = {}\n",
    "index2word = {}\n",
    "\n",
    "i = 0\n",
    "for words in lyrics_list:\n",
    "    for word in words:\n",
    "        if word not in word2index:\n",
    "            word2index[word] = i\n",
    "            index2word[i] = word\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nueOEx287Hpm",
    "outputId": "c6660bfe-a513-424d-95bd-a8b8400255d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2101"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BwIpjwU_8YJB"
   },
   "outputs": [],
   "source": [
    "# 建立數據集\n",
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, lyrics_list, word2index, num_unrollings=10):\n",
    "        self.word2index = word2index\n",
    "        self.lyrics_list = lyrics_list\n",
    "        self.sample = []\n",
    "        \n",
    "        for lyrics in lyrics_list:\n",
    "            for i in range(len(lyrics) - num_unrollings + 1):\n",
    "                sample = lyrics[i:i+num_unrollings]\n",
    "                self.sample.append(sample)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source = self.sample[idx]\n",
    "        \n",
    "        data_X = [self.word2index[w] for w in source[:-1]]\n",
    "        target_Y = self.word2index[source[-1]]\n",
    "        \n",
    "        data_X = torch.tensor(data_X, dtype=torch.long)\n",
    "        target_Y = torch.tensor(target_Y, dtype=torch.long)\n",
    "        \n",
    "        return data_X, target_Y\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_L7UokS6_W7O"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "dataset = LyricsDataset(lyrics_list, word2index)\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57223"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10]), tensor(11))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_HV3bcPM_l7X"
   },
   "outputs": [],
   "source": [
    "# 建立模型 inputs > nn.Embedding > nn.LSTM > nn.Dropout > 取最後一個 state > nn.Linear > softmax\n",
    "class LM_LSTM(nn.Module):\n",
    "    def __init__(self, n_hidden, vocab_size, num_layers, dropout_ratio):\n",
    "        super(LM_LSTM, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, n_hidden)\n",
    "        \n",
    "        self.Lstm = nn.LSTM(input_size=n_hidden, hidden_size=n_hidden*2, \n",
    "                            num_layers=num_layers, dropout=dropout_ratio)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=n_hidden*2, out_features=vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        embedded = self.embedding(inputs)\n",
    "        embedded = embedded.transpose(0, 1) # [n_step, batch_size, n_class]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.Lstm(embedded)\n",
    "        \n",
    "        outputs = self.dropout(outputs)  # [n_step, batch_size, n_hidden]\n",
    "        output = outputs[-1]  # [batch_size, n_hidden]\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-tNgfswV_nc1"
   },
   "outputs": [],
   "source": [
    "def train_batch(model, data, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    inputs, targets = [d.to(device) for d in data]\n",
    "\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_QVIJqHRsnX",
    "outputId": "3ad0be24-37a2-463c-90db-206ca71f8251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 train_loss:  5.553820373473559\n",
      "epoch  2 train_loss:  4.990153993702863\n",
      "epoch  3 train_loss:  4.475222526804815\n",
      "epoch  4 train_loss:  4.005738793288062\n",
      "epoch  5 train_loss:  3.5782345234196757\n",
      "epoch  6 train_loss:  3.183004314175352\n",
      "epoch  7 train_loss:  2.823365365296653\n",
      "epoch  8 train_loss:  2.4952560051687924\n",
      "epoch  9 train_loss:  2.203695993543623\n",
      "epoch  10 train_loss:  1.9366773782638806\n",
      "Example: \"摸不到的顏色 是否\"+\"就\"\n",
      "Example: \" 只留下結果 時間\"+\"遺\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  11 train_loss:  1.710828801960338\n",
      "epoch  12 train_loss:  1.5125062583120843\n",
      "epoch  13 train_loss:  1.3371879967686064\n",
      "epoch  14 train_loss:  1.1865977422253153\n",
      "epoch  15 train_loss:  1.0542544796126718\n",
      "epoch  16 train_loss:  0.9410625085084389\n",
      "epoch  17 train_loss:  0.8456063230153976\n",
      "epoch  18 train_loss:  0.7546933578132027\n",
      "epoch  19 train_loss:  0.680472565837215\n",
      "epoch  20 train_loss:  0.6125455360378599\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"偷\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  21 train_loss:  0.5549739866757691\n",
      "epoch  22 train_loss:  0.5045378890171781\n",
      "epoch  23 train_loss:  0.46437153078672566\n",
      "epoch  24 train_loss:  0.43537743467649886\n",
      "epoch  25 train_loss:  0.40466095483005377\n",
      "epoch  26 train_loss:  0.36961045128620484\n",
      "epoch  27 train_loss:  0.35083030684869715\n",
      "epoch  28 train_loss:  0.32744594448013536\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f385b16e1265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtot_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-f967cfc05dca>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(model, data, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-ccb569b78afe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [n_step, batch_size, n_class]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [n_step, batch_size, n_hidden]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 662\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LM_LSTM(128, len(word2index), 2, 0.2)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "criterion.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(1, 1 + epochs):\n",
    "    tot_train_loss = 0\n",
    "    tot_train_count = 0\n",
    "\n",
    "    for train_data in train_loader:\n",
    "        loss = train_batch(model, train_data, criterion, optimizer, device)\n",
    "\n",
    "        tot_train_loss += loss\n",
    "        tot_train_count += train_data[0].size(0)\n",
    "\n",
    "    print('epoch ', epoch, 'train_loss: ', tot_train_loss / tot_train_count)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        for idx in [0, 50, 99]:\n",
    "            input_batch = dataset[idx][0].unsqueeze(0).to(device)\n",
    "            predict = model(input_batch).argmax(dim=-1).item()\n",
    "            print('Example: \"{}\"+\"{}\"'.format(dataset.sample[idx][:-1], index2word[predict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anMER7TJTWKy",
    "outputId": "8ad0434c-91ee-4542-cc3a-bf881d2fb379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<SWhereBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eating/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid multinomial distribution (sum of probabilities <= 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f1f994c2be54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid multinomial distribution (sum of probabilities <= 0)"
     ]
    }
   ],
   "source": [
    "# 模型inference\n",
    "pre_text = '給我一首歌'\n",
    "generate_len = 2\n",
    "prob_threshold = 0.01\n",
    "\n",
    "result = [word2index[c] for c in pre_text]\n",
    "for _ in range(generate_len):\n",
    "    input_example = torch.tensor([result], dtype=torch.long, device=device)\n",
    "    logit = model(input_example)\n",
    "\n",
    "    probs = F.softmax(logit)\n",
    "\n",
    "    # if probs > prob_threshold output=probs else torch.zeros_like(probs)\n",
    "    probs = torch.where(probs > prob_threshold, probs, torch.zeros_like(probs))\n",
    "    print(probs)\n",
    "    probs=torch.zeros_like(probs)    \n",
    "    predict = torch.multinomial(probs, 1).item()\n",
    "    print(predict)\n",
    "    result += [predict]\n",
    "\n",
    "print(''.join([index2word[i] for i in result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "NeJ2a5VM8OPM"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid multinomial distribution (sum of probabilities <= 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-f5519f428e80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid multinomial distribution (sum of probabilities <= 0)"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0., 0., 0., 0.]], dtype=torch.float)\n",
    "torch.multinomial(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm_writer_hw.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
